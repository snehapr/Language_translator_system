{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the sentences in the .txt file with '\\t'\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"spa-eng\\spa.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_eng = to_lines(data)\n",
    "spa_eng = array(spa_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Go.' 'Ve.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)']\n",
      " ['Go.' 'Vete.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)']\n",
      " ['Go.' 'Vaya.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)']\n",
      " ...\n",
      " ['If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.'\n",
      "  'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #953962 (CK) & #1218695 (marcelostockle)']\n",
      " ['It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.'\n",
      "  'Puede que sea imposible obtener un corpus completamente libre de errores debido a la naturaleza de este tipo de esfuerzo de colaboración. Sin embargo, si animamos a los miembros a contribuir frases en sus propios idiomas en lugar de experimentar con los idiomas que están aprendiendo, podríamos ser capaces de minimizar los errores.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2024159 (CK) & #4463195 (cueyayotl)']\n",
      " [\"One day, I woke up to find that God had put hair on my face. I shaved it off. The next day, I found that God had put it back on my face, so I shaved it off again. On the third day, when I found that God had put hair back on my face again, I decided to let God have his way. That's why I have a beard.\"\n",
      "  'Un día, me desperté y vi que Dios me había puesto pelo en la cara. Me lo afeité. Al día siguiente, vi que Dios me lo había vuelto a poner en la cara, así que me lo afeité otra vez. Al tercer día, cuando vi que Dios me había puesto pelo en la cara de nuevo, decidí que Dios se saliera con la suya. Por eso tengo barba.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #10104877 (CK) & #10106093 (manufrutos)']]\n"
     ]
    }
   ],
   "source": [
    "#print the seperated words from the .txt file\n",
    "print(spa_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134736\n"
     ]
    }
   ],
   "source": [
    "print(len(spa_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use only first 50,000 sentences among the total ones & consider only first 2 columns with spanish & english words\n",
    "spa_eng = spa_eng[:50000,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Ve.'],\n",
       "       ['Go.', 'Vete.'],\n",
       "       ['Go.', 'Vaya.'],\n",
       "       ...,\n",
       "       ['Work never ends, does it?',\n",
       "        'El trabajo nunca se acaba, ¿verdad?'],\n",
       "       ['Would you go out with me?', '¿Saldrías conmigo?'],\n",
       "       ['Would you let me through?', '¿Me dejarías pasar?']],\n",
       "      dtype='<U332')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation (data cleaning)\n",
    "spa_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in spa_eng[:,0]]\n",
    "spa_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in spa_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Ve'],\n",
       "       ['Go', 'Vete'],\n",
       "       ['Go', 'Vaya'],\n",
       "       ...,\n",
       "       ['Work never ends does it', 'El trabajo nunca se acaba ¿verdad'],\n",
       "       ['Would you go out with me', '¿Saldrías conmigo'],\n",
       "       ['Would you let me through', '¿Me dejarías pasar']], dtype='<U332')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to lowercase(data cleaning)\n",
    "for i in range(len(spa_eng)):\n",
    "    spa_eng[i,0] = spa_eng[i,0].lower()\n",
    "    spa_eng[i,1] = spa_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 've'],\n",
       "       ['go', 'vete'],\n",
       "       ['go', 'vaya'],\n",
       "       ...,\n",
       "       ['work never ends does it', 'el trabajo nunca se acaba ¿verdad'],\n",
       "       ['would you go out with me', '¿saldrías conmigo'],\n",
       "       ['would you let me through', '¿me dejarías pasar']], dtype='<U332')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "spa_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in spa_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in spa_eng[:,1]:\n",
    "      spa_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'spa':spa_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#print the max english sentence length\n",
    "print(max(eng_l))\n",
    "#print the max spanish sentence length\n",
    "print(max(spa_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer (tokenization)\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6883\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(spa_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Vocabulary Size: 14061\n"
     ]
    }
   ],
   "source": [
    "# prepare Spanish tokenizer\n",
    "spa_tokenizer = tokenization(spa_eng[:, 1])\n",
    "spa_vocab_size = len(spa_tokenizer.word_index) + 1\n",
    "\n",
    "spa_length = 8\n",
    "print('Spanish Vocabulary Size: %d' % spa_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences (padding)\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(spa_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data by encoding spanish sentences as input sequences and english as output sequences\n",
    "trainX = encode_sequences(spa_tokenizer, spa_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data by encoding spanish sentences as input sequences and english as output sequences\n",
    "testX = encode_sequences(spa_tokenizer, spa_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "\n",
    "\n",
    "#-----------Model Architecture-----------------\n",
    "\n",
    "#INPUT-->EMBEDDING-->ENCODER-->DECODER-->DENSE-->OUTPUT\n",
    "\n",
    "#----------------------------------------------\n",
    "\n",
    "#For the encoder, we will use an embedding layer and an LSTM layer\n",
    "#For the decoder, we will use another LSTM layer followed by a dense layer\n",
    "\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    #encoder\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    #decoder\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(spa_vocab_size, eng_vocab_size, spa_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.h1.26_jul_21'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 106s 2s/step - loss: 4.7383 - val_loss: 3.2027\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.20273, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "63/63 [==============================] - 100s 2s/step - loss: 3.1365 - val_loss: 3.1020\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.20273 to 3.10199, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "63/63 [==============================] - 98s 2s/step - loss: 2.9808 - val_loss: 2.9272\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.10199 to 2.92720, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "63/63 [==============================] - 103s 2s/step - loss: 2.8513 - val_loss: 2.8584\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.92720 to 2.85837, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "63/63 [==============================] - 105s 2s/step - loss: 2.7202 - val_loss: 2.7402\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.85837 to 2.74021, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "63/63 [==============================] - 109s 2s/step - loss: 2.5755 - val_loss: 2.6054\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.74021 to 2.60541, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "63/63 [==============================] - 107s 2s/step - loss: 2.4156 - val_loss: 2.5174\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.60541 to 2.51739, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "63/63 [==============================] - 123s 2s/step - loss: 2.2694 - val_loss: 2.4114\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.51739 to 2.41136, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "63/63 [==============================] - 147s 2s/step - loss: 2.1292 - val_loss: 2.3024\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.41136 to 2.30238, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "63/63 [==============================] - 141s 2s/step - loss: 2.0000 - val_loss: 2.2621\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.30238 to 2.26212, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "63/63 [==============================] - 149s 2s/step - loss: 1.8933 - val_loss: 2.1695\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.26212 to 2.16949, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "63/63 [==============================] - 150s 2s/step - loss: 1.7813 - val_loss: 2.1032\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.16949 to 2.10320, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "63/63 [==============================] - 146s 2s/step - loss: 1.6809 - val_loss: 2.0801\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.10320 to 2.08014, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "63/63 [==============================] - 140s 2s/step - loss: 1.5864 - val_loss: 2.0256\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.08014 to 2.02562, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "63/63 [==============================] - 122s 2s/step - loss: 1.5046 - val_loss: 1.9645\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.02562 to 1.96451, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "63/63 [==============================] - 122s 2s/step - loss: 1.4122 - val_loss: 1.9288\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.96451 to 1.92884, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "63/63 [==============================] - 130s 2s/step - loss: 1.3279 - val_loss: 1.9224\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.92884 to 1.92241, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "63/63 [==============================] - 149s 2s/step - loss: 1.2500 - val_loss: 1.8798\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.92241 to 1.87980, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "63/63 [==============================] - 151s 2s/step - loss: 1.1654 - val_loss: 1.8411\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.87980 to 1.84106, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "63/63 [==============================] - 152s 2s/step - loss: 1.0974 - val_loss: 1.8509\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.84106\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 152s 2s/step - loss: 1.0353 - val_loss: 1.7957\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.84106 to 1.79570, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "63/63 [==============================] - 130s 2s/step - loss: 0.9555 - val_loss: 1.7788\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.79570 to 1.77875, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.8943 - val_loss: 1.7668\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.77875 to 1.76684, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "63/63 [==============================] - 110s 2s/step - loss: 0.8398 - val_loss: 1.7332\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.76684 to 1.73315, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "63/63 [==============================] - 113s 2s/step - loss: 0.7747 - val_loss: 1.7337\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.73315\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 122s 2s/step - loss: 0.7183 - val_loss: 1.7210\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.73315 to 1.72102, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "63/63 [==============================] - 112s 2s/step - loss: 0.6647 - val_loss: 1.7083\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.72102 to 1.70831, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "63/63 [==============================] - 114s 2s/step - loss: 0.6117 - val_loss: 1.7106\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.70831\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 121s 2s/step - loss: 0.5669 - val_loss: 1.6988\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.70831 to 1.69882, saving model to model.h1.26_jul_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.26_jul_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "63/63 [==============================] - 114s 2s/step - loss: 0.5236 - val_loss: 1.7020\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.69882\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare the training loss and the validation loss.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sphaniraj\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#we can load the saved model and make predictions on the unseen data – testX.\n",
    "model = load_model('model.h1.26_jul_21')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These predictions are in integers ,need to convert to their corresponding words.\n",
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                    temp.append('')\n",
    "            else:\n",
    "                    temp.append(t)\n",
    "        else:\n",
    "                if(t == None):\n",
    "                        temp.append('')\n",
    "                else:\n",
    "                        temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tom has a big problem</td>\n",
       "      <td>tom has a real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont yell</td>\n",
       "      <td>dont yell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leave tomorrow</td>\n",
       "      <td>go yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate karaoke</td>\n",
       "      <td>i hate tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they didnt do anything</td>\n",
       "      <td>they didnt nothing anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>could you stay a minute</td>\n",
       "      <td>can you have a minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>do you know how to dance</td>\n",
       "      <td>can you dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i loosened my shoelaces</td>\n",
       "      <td>my of my shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tom seldom laughs</td>\n",
       "      <td>tom rarely laughs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im simply doing my job</td>\n",
       "      <td>im am my  job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tom was young</td>\n",
       "      <td>tom was young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>row faster</td>\n",
       "      <td>eat more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>its my treat</td>\n",
       "      <td>its toms new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>im your boss</td>\n",
       "      <td>im your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>you will conform</td>\n",
       "      <td>ill get in the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual                        predicted\n",
       "0      tom has a big problem               tom has a real    \n",
       "1                  dont yell                  dont yell      \n",
       "2             leave tomorrow                go yourself      \n",
       "3             i hate karaoke             i hate tomatoes     \n",
       "4     they didnt do anything  they didnt nothing anything    \n",
       "5    could you stay a minute         can you have a minute   \n",
       "6   do you know how to dance               can you dance     \n",
       "7    i loosened my shoelaces               my of my shoes    \n",
       "8          tom seldom laughs           tom rarely laughs     \n",
       "9     im simply doing my job                 im am my  job   \n",
       "10             tom was young               tom was young     \n",
       "11                row faster                   eat more      \n",
       "12              its my treat                its toms new     \n",
       "13              im your boss                    im your      \n",
       "14          you will conform               ill get in the    "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>i know who got hurt</td>\n",
       "      <td>i know who they is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>he can be trusted</td>\n",
       "      <td>he can be on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>i dont wear a watch</td>\n",
       "      <td>i dont have my tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>he is wearing glasses</td>\n",
       "      <td>he is wearing glasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>which dog is yours</td>\n",
       "      <td>which your is yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>no one will survive</td>\n",
       "      <td>no one will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>please be patient</td>\n",
       "      <td>please be patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>finish this</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>i asked a favor of him</td>\n",
       "      <td>i asked him a favor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>im from the fbi</td>\n",
       "      <td>im on the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>show me how to do it</td>\n",
       "      <td>we me to  do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>she is wearing a hat</td>\n",
       "      <td>he has a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>keep away from me</td>\n",
       "      <td>keep away from me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>you took the wrong key</td>\n",
       "      <td>i me was full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>isnt that terrific</td>\n",
       "      <td>can i borrow that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual                  predicted\n",
       "9985     i know who got hurt      i know who they is   \n",
       "9986       he can be trusted           he can be on    \n",
       "9987     i dont wear a watch      i dont have my tie   \n",
       "9988   he is wearing glasses  he is wearing glasses    \n",
       "9989      which dog is yours    which your is yours    \n",
       "9990     no one will survive           no one will     \n",
       "9991       please be patient     please be patient     \n",
       "9992             finish this                this       \n",
       "9993  i asked a favor of him     i asked him a favor   \n",
       "9994         im from the fbi             im on the     \n",
       "9995    show me how to do it            we me to  do   \n",
       "9996    she is wearing a hat              he has a     \n",
       "9997       keep away from me      keep away from me    \n",
       "9998  you took the wrong key          i me was full    \n",
       "9999      isnt that terrific      can i borrow that    "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>i need a crew</td>\n",
       "      <td>i need a paper days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>tom didnt want anything</td>\n",
       "      <td>tom didnt want anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6347</th>\n",
       "      <td>they enjoyed themselves</td>\n",
       "      <td>they were getting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>youll have to trust me</td>\n",
       "      <td>you have to  me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>youre not a doctor</td>\n",
       "      <td>youre not a doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>you should stop that</td>\n",
       "      <td>you should see that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>tom couldve been killed</td>\n",
       "      <td>tom never been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>i met your friend</td>\n",
       "      <td>i met my  friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>bring a bucket of apples</td>\n",
       "      <td>get your umbrella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>tom and mary are tired</td>\n",
       "      <td>tom and mary crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>he is skating</td>\n",
       "      <td>she in  the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>do you have doubts</td>\n",
       "      <td>do you have any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>when will we go home</td>\n",
       "      <td>when will you go home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>im quite tired</td>\n",
       "      <td>im very tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>ive already told tom</td>\n",
       "      <td>ive already told tom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        actual                    predicted\n",
       "5219             i need a crew       i need a paper days   \n",
       "2150   tom didnt want anything  tom didnt want anything    \n",
       "6347   they enjoyed themselves       they were getting     \n",
       "8579    youll have to trust me           you have to  me   \n",
       "1416        youre not a doctor       youre not a doctor    \n",
       "1466      you should stop that      you should see that    \n",
       "7613   tom couldve been killed          tom never been     \n",
       "3060         i met your friend          i met my  friend   \n",
       "895   bring a bucket of apples       get your umbrella     \n",
       "7318    tom and mary are tired       tom and mary crazy    \n",
       "2682             he is skating              she in  the    \n",
       "387         do you have doubts          do you have any    \n",
       "6485      when will we go home     when will you go home   \n",
       "3578            im quite tired           im very tired     \n",
       "7205      ive already told tom     ive already told tom    "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'él es tu padre'\n",
    "len1=max(sentence.split(), key=len)\n",
    "b1=len(len1)\n",
    "sentence = [spa_tokenizer.word_index[word] for word in sentence.split()]\n",
    "sentence = pad_sequences([sentence], maxlen=b1, padding='post')\n",
    "predictions = model.predict_classes(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85,  21, 222,   0,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in predictions:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                    temp.append('')\n",
    "            else:\n",
    "                    temp.append(t)\n",
    "        else:\n",
    "                if(t == None):\n",
    "                        temp.append('')\n",
    "                else:\n",
    "                        temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hes your father     ']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
